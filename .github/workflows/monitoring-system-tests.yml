name: Monitoring System Test Suite

on:
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM UTC
  workflow_dispatch:
    inputs:
      test_scope:
        description: 'Scope of tests to run'
        required: false
        default: 'full'
        type: choice
        options:
          - full
          - quick
          - components
          - integration
      verbose:
        description: 'Enable verbose output'
        required: false
        default: false
        type: boolean

permissions:
  contents: read
  actions: read

jobs:
  test_credit_guard:
    runs-on: [self-hosted, monitoring]
    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5

      - name: Test Credit Guard Logic
        run: |
          echo "🛡️ Testing credit guard logic..."

          # Test percentage-based thresholds
          test_threshold() {
            local usage=$1
            local threshold=$2
            local expected=$3

            if (( $(echo "$usage > $threshold" | bc -l) )); then
              result="$expected"
            else
              result="below"
            fi

            echo "Usage $usage% vs threshold $threshold% = $result"
            return 0
          }

          # Test various scenarios
          test_threshold 75 80 "below"
          test_threshold 85 80 "above"
          test_threshold 95 90 "above"
          test_threshold 50 90 "below"

          echo "✅ Credit guard logic tests passed"

      - name: Validate Credit Guard Workflows
        run: |
          echo "🔍 Validating credit guard workflow files..."

          # Check if enhanced credit guard workflow exists and is valid
          if [ -f ".github/workflows/actions-credit-guard-enhanced.yml" ]; then
            echo "✅ Enhanced credit guard workflow found"

            # Basic YAML syntax check
            if python3 -c "import yaml; yaml.safe_load(open('.github/workflows/actions-credit-guard-enhanced.yml'))"; then
              echo "✅ Enhanced credit guard workflow YAML is valid"
            else
              echo "❌ Enhanced credit guard workflow YAML is invalid"
              exit 1
            fi
          else
            echo "❌ Enhanced credit guard workflow not found"
            exit 1
          fi

  test_usage_tracking:
    runs-on: [self-hosted, monitoring]
    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5

      - name: Test Usage Tracking
        run: |
          echo "📊 Testing usage tracking system..."

          # Test metrics collection
          if [ -f ".github/workflows/track-actions-usage.yml" ]; then
            echo "✅ Usage tracking workflow found"

            # Check for required permissions
            if grep -q "contents: read" .github/workflows/track-actions-usage.yml; then
              echo "✅ Usage tracking has correct permissions"
            else
              echo "⚠️ Usage tracking may lack required permissions"
            fi
          else
            echo "❌ Usage tracking workflow not found"
            exit 1
          fi

      - name: Test Metrics Storage
        run: |
          echo "💾 Testing metrics storage..."

          # Check if metrics directory exists or can be created
          mkdir -p metrics

          # Test metrics file creation
          cat > metrics/test-usage-$(date +%s).json << EOF
          {
            "percentage_used": 45.5,
            "remaining_minutes": 15425,
            "included_minutes": 3000,
            "timestamp": "$(date -Iseconds)",
            "test": true
          }
          EOF

          echo "✅ Metrics storage test passed"

  test_alert_system:
    runs-on: [self-hosted, monitoring]
    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5

      - name: Test Alert System
        run: |
          echo "🚨 Testing alert system..."

          if [ -f ".github/workflows/usage-alerts.yml" ]; then
            echo "✅ Alert system workflow found"

            # Test alert level determination logic
            test_alert_level() {
              local usage=$1
              local expected=$2

              if (( $(echo "$usage >= 95" | bc -l) )); then
                level="critical"
              elif (( $(echo "$usage >= 80" | bc -l) )); then
                level="warning"
              else
                level="normal"
              fi

              if [ "$level" = "$expected" ]; then
                echo "✅ Alert level test passed: $usage% -> $level"
              else
                echo "❌ Alert level test failed: $usage% -> $level (expected $expected)"
              fi
            }

            test_alert_level 50 "normal"
            test_alert_level 85 "warning"
            test_alert_level 97 "critical"

          else
            echo "❌ Alert system workflow not found"
            exit 1
          fi

  test_trend_analysis:
    runs-on: [self-hosted, monitoring]
    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5

      - name: Test Trend Analysis
        run: |
          echo "📈 Testing trend analysis system..."

          if [ -f ".github/workflows/usage-trend-analysis.yml" ]; then
            echo "✅ Trend analysis workflow found"

            # Test basic trend calculation logic
            test_trend() {
              local values=("$@")
              local count=${#values[@]}

              if [ $count -lt 2 ]; then
                echo "Not enough data points for trend analysis"
                return
              fi

              # Simple linear trend calculation
              local sum_x=0
              local sum_y=0
              local sum_xy=0
              local sum_xx=0

              for i in "${!values[@]}"; do
                local x=$i
                local y=${values[$i]}
                sum_x=$((sum_x + x))
                sum_y=$((sum_y + y))
                sum_xy=$((sum_xy + x * y))
                sum_xx=$((sum_xx + x * x))
              done

              local n=$count
              local slope=$(( (n * sum_xy - sum_x * sum_y) / (n * sum_xx - sum_x * sum_x) ))

              if [ $slope -gt 0 ]; then
                trend="increasing"
              elif [ $slope -lt 0 ]; then
                trend="decreasing"
              else
                trend="stable"
              fi

              echo "Trend analysis: $trend (slope: $slope)"
            }

            # Test with sample data
            test_trend 10 15 20 25  # Should be increasing
            test_trend 25 20 15 10  # Should be decreasing
            test_trend 20 20 20 20  # Should be stable

            echo "✅ Trend analysis logic tests passed"

          else
            echo "❌ Trend analysis workflow not found"
            exit 1
          fi

  test_autoscaling:
    runs-on: [self-hosted, monitoring]
    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5

      - name: Test Auto-Scaling Logic
        run: |
          echo "🔧 Testing auto-scaling system..."

          if [ -f ".github/workflows/swarm-autoscaling.yml" ]; then
            echo "✅ Auto-scaling workflow found"

            # Test scaling decision logic
            test_scaling_decision() {
              local usage=$1
              local hour=$2
              local day=$3
              local expected_action=$4

              local action="none"

              # Emergency stop
              if (( $(echo "$usage > 95" | bc -l) )); then
                action="emergency_stop"
              # Peak hours scaling
              elif [ "$hour" -ge 9 ] && [ "$hour" -le 18 ] && [ "$day" -ge 1 ] && [ "$day" -le 5 ]; then
                if (( $(echo "$usage > 70" | bc -l) )); then
                  action="scale_up"
                fi
              # Off-peak scaling
              elif [ "$hour" -lt 6 ] || [ "$hour" -gt 22 ] || [ "$day" -eq 0 ] || [ "$day" -eq 6 ]; then
                action="scale_down"
              fi

              if [ "$action" = "$expected_action" ]; then
                echo "✅ Scaling decision test passed: usage=$usage%, hour=$hour, day=$day -> $action"
              else
                echo "❌ Scaling decision test failed: got $action, expected $expected_action"
              fi
            }

            # Test various scenarios
            test_scaling_decision 50 12 2 "none"        # Normal weekday
            test_scaling_decision 85 14 3 "scale_up"    # High usage peak hours
            test_scaling_decision 60 2 4 "scale_down"   # Off-peak hours
            test_scaling_decision 97 10 1 "emergency_stop"  # Critical usage

            echo "✅ Auto-scaling logic tests passed"

          else
            echo "❌ Auto-scaling workflow not found"
            exit 1
          fi

  test_pre_trigger_checks:
    runs-on: [self-hosted, monitoring]
    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5

      - name: Test Pre-Trigger Health Checks
        run: |
          echo "🏥 Testing pre-trigger health check system..."

          if [ -f ".github/workflows/pre-trigger-health-check.yml" ]; then
            echo "✅ Pre-trigger health check workflow found"

            # Test health check decision logic
            test_health_decision() {
              local usage=$1
              local remaining=$2
              local expected=$3

              local can_proceed="true"

              if (( $(echo "$usage > 95" | bc -l) )); then
                can_proceed="false"
              fi

              if [ "$remaining" -lt 100 ]; then
                can_proceed="false"
              fi

              if [ "$can_proceed" = "$expected" ]; then
                echo "✅ Health decision test passed: usage=$usage%, remaining=$remaining -> $can_proceed"
              else
                echo "❌ Health decision test failed: got $can_proceed, expected $expected"
              fi
            }

            # Test scenarios
            test_health_decision 50 15000 "true"   # Normal
            test_health_decision 97 5000 "false"   # Critical usage
            test_health_decision 60 50 "false"     # Low minutes
            test_health_decision 85 200 "true"     # High usage but enough minutes

            echo "✅ Pre-trigger health check logic tests passed"

          else
            echo "❌ Pre-trigger health check workflow not found"
            exit 1
          fi

  test_dashboard:
    runs-on: [self-hosted, monitoring]
    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5

      - name: Test Dashboard System
        run: |
          echo "📊 Testing dashboard system..."

          if [ -f ".github/workflows/dashboard-update.yml" ]; then
            echo "✅ Dashboard update workflow found"
          else
            echo "❌ Dashboard update workflow not found"
            exit 1
          fi

          if [ -f "docs/dashboard/index.html" ]; then
            echo "✅ Dashboard HTML found"

            # Check for required elements
            if grep -q "chart.js" docs/dashboard/index.html; then
              echo "✅ Dashboard includes Chart.js"
            else
              echo "⚠️ Dashboard missing Chart.js"
            fi

            if grep -q "usage-percentage" docs/dashboard/index.html; then
              echo "✅ Dashboard has usage display elements"
            else
              echo "⚠️ Dashboard missing usage display elements"
            fi

          else
            echo "❌ Dashboard HTML not found"
            exit 1
          fi

  integration_test:
    needs: [test_credit_guard, test_usage_tracking, test_alert_system, test_trend_analysis, test_autoscaling, test_pre_trigger_checks, test_dashboard]
    runs-on: [self-hosted, monitoring]
    if: ${{ github.event.inputs.test_scope == 'full' || github.event.inputs.test_scope == 'integration' }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5

      - name: Run Integration Tests
        run: |
          echo "🔗 Running integration tests..."

          # Test workflow dependencies and data flow
          echo "Testing workflow interconnections..."

          # Check if workflows reference each other correctly
          if grep -q "track-actions-usage.yml" .github/workflows/dashboard-update.yml; then
            echo "✅ Dashboard update references usage tracking"
          else
            echo "⚠️ Dashboard update may not reference usage tracking"
          fi

          if grep -q "usage-alerts.yml" .github/workflows/actions-credit-guard-enhanced.yml; then
            echo "✅ Credit guard references alert system"
          else
            echo "⚠️ Credit guard may not reference alert system"
          fi

          # Test data flow between components
          echo "Testing data flow..."

          # Create test data and verify it flows through the system
          mkdir -p test-data
          echo '{"test": true, "integration": "passed"}' > test-data/integration-test.json

          if [ -f "test-data/integration-test.json" ]; then
            echo "✅ Data flow test passed"
          fi

          echo "✅ Integration tests completed"

  generate_test_report:
    needs: [test_credit_guard, test_usage_tracking, test_alert_system, test_trend_analysis, test_autoscaling, test_pre_trigger_checks, test_dashboard, integration_test]
    if: always()
    runs-on: [self-hosted, monitoring]
    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5

      - name: Generate Test Report
        run: |
          echo "📋 Generating monitoring system test report..."

          # Collect test results
          TEST_RESULTS=$(cat << EOF
          {
            "timestamp": "$(date -Iseconds)",
            "test_suite": "monitoring-system-test-suite",
            "scope": "${{ github.event.inputs.test_scope }}",
            "results": {
              "credit_guard_test": "${{ needs.test_credit_guard.result }}",
              "usage_tracking_test": "${{ needs.test_usage_tracking.result }}",
              "alert_system_test": "${{ needs.test_alert_system.result }}",
              "trend_analysis_test": "${{ needs.test_trend_analysis.result }}",
              "autoscaling_test": "${{ needs.test_autoscaling.result }}",
              "pre_trigger_test": "${{ needs.test_pre_trigger_checks.result }}",
              "dashboard_test": "${{ needs.test_dashboard.result }}",
              "integration_test": "${{ needs.integration_test.result }}"
            },
            "overall_status": "${{ needs.integration_test.result }}"
          }
          EOF
          )

          mkdir -p test-reports
          echo "$TEST_RESULTS" > test-reports/test-suite-$(date +%Y-%m-%d_%H-%M-%S).json

          echo "📊 Test Results Summary:"
          echo "$TEST_RESULTS" | jq .

      - name: Send Test Notification
        run: |
          OVERALL_STATUS="${{ needs.integration_test.result }}"
          TEST_SCOPE="${{ github.event.inputs.test_scope }}"

          if [ -n "${{ secrets.SLACK_WEBHOOK_URL }}" ]; then
            if [ "$OVERALL_STATUS" = "success" ]; then
              COLOR="good"
              TITLE="✅ Monitoring System Tests Passed"
              TEXT="All monitoring system components are functioning correctly."
            else
              COLOR="danger"
              TITLE="❌ Monitoring System Tests Failed"
              TEXT="Some monitoring system components failed testing. Check the test report for details."
            fi

            PAYLOAD=$(cat <<EOF
            {
              "attachments": [
                {
                  "color": "$COLOR",
                  "title": "$TITLE",
                  "text": "$TEXT",
                  "fields": [
                    {
                      "title": "Test Scope",
                      "value": "$TEST_SCOPE",
                      "short": true
                    },
                    {
                      "title": "Overall Status",
                      "value": "$OVERALL_STATUS",
                      "short": true
                    },
                    {
                      "title": "Test Time",
                      "value": "$(date)",
                      "short": true
                    }
                  ],
                  "actions": [
                    {
                      "type": "button",
                      "text": "View Test Report",
                      "url": "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
                    }
                  ],
                  "footer": "Monitoring System Test Suite",
                  "ts": $(date +%s)
                }
              ]
            }
          EOF
          )

            curl -X POST -H 'Content-type: application/json' \
              --data "$PAYLOAD" \
              "${{ secrets.SLACK_WEBHOOK_URL }}" || echo "Test notification failed"
          fi

      - name: Generate Summary Report
        run: |
          OVERALL_STATUS="${{ needs.integration_test.result }}"
          TEST_SCOPE="${{ github.event.inputs.test_scope }}"

          echo "## 🧪 Monitoring System Test Suite Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Component | Status | Details |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|--------|---------|" >> $GITHUB_STEP_SUMMARY
          echo "| Credit Guard | ${{ needs.test_credit_guard.result }} | Logic validation |" >> $GITHUB_STEP_SUMMARY
          echo "| Usage Tracking | ${{ needs.test_usage_tracking.result }} | Metrics collection |" >> $GITHUB_STEP_SUMMARY
          echo "| Alert System | ${{ needs.test_alert_system.result }} | Notification logic |" >> $GITHUB_STEP_SUMMARY
          echo "| Trend Analysis | ${{ needs.test_trend_analysis.result }} | Forecasting algorithms |" >> $GITHUB_STEP_SUMMARY
          echo "| Auto-Scaling | ${{ needs.test_autoscaling.result }} | Runner management |" >> $GITHUB_STEP_SUMMARY
          echo "| Pre-Trigger Checks | ${{ needs.test_pre_trigger_checks.result }} | Health validation |" >> $GITHUB_STEP_SUMMARY
          echo "| Dashboard | ${{ needs.test_dashboard.result }} | UI and data display |" >> $GITHUB_STEP_SUMMARY
          echo "| Integration | ${{ needs.integration_test.result }} | Component interaction |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 📊 Overall Status:" >> $GITHUB_STEP_SUMMARY
          echo "- **Test Scope:** $TEST_SCOPE" >> $GITHUB_STEP_SUMMARY
          echo "- **Result:** $OVERALL_STATUS" >> $GITHUB_STEP_SUMMARY
          echo "- **Timestamp:** $(date)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "*Test suite runs daily and validates all monitoring system components.*" >> $GITHUB_STEP_SUMMARY
          echo "*Failed tests indicate potential issues that should be investigated.*" >> $GITHUB_STEP_SUMMARY
